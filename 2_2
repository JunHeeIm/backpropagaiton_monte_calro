import tensorflow as tf
import numpy as np
import random
import time
import matplotlib.pyplot as plt

from tensorflow.keras import datasets
from tensorflow.keras.datasets import mnist  # 라이브러리가 기본으로 제공하는 mnist 데이터셋
from tensorflow.keras.utils import to_categorical  # one-hot encoding 을 위한 함수

mnist = datasets.mnist
(train_x, train_y),(test_x, test_y) = mnist.load_data()

print(train_x.shape)
print(train_y.shape)

number_of_classes = len(set(train_y))
from tensorflow.keras.utils import to_categorical

train_y = to_categorical(train_y, number_of_classes)  # 원-핫 인코딩. 1차원 -> 2차원
test_y = to_categorical(test_y, number_of_classes)

print(f"train_y_shape: {train_y.shape}")  # y_train_shape: (60000, 10)
print(f"test_y_shape: {test_y.shape}")  # y_test_shape: (10000, 10)


train_x = train_x / 255.0
test_x = test_x / 255
train_x = train_x.reshape(-1, 28*28)  # 3차원 -> 2차원
test_x = test_x.reshape(-1, 28*28)

w1 = np.random.uniform(-1, 1, ( 28*28, 128))
b1 = np.random.uniform(-1, 1, ( 128))

w2 = np.random.uniform(-1, 1, (128, 10))
b2 = np.random.uniform(-1, 1, (10))

# print(w1, b1, w2, b2)


train_x =train_x[999:1000,:]
train_y =train_y[999:1000,:]

L = []


a = 0.01

for i in range(5000):

  L1 = np.add(np.matmul(train_x, w1), b1)
  L2 = np.add(np.matmul(L1, w2), b2)

  output = softmax(L2)


  predict = np.max(output)
  target = np.max(train_y)


  loss = -target*np.log(predict)



  dw2 = np.matmul(L1.T, (train_y-output))
  db2 = np.matmul((train_y-output).T,np.ones(1))

  dw1 = np.matmul(train_x.T, np.matmul(train_y-output, dw2.T))
  db1 = np.matmul(np.matmul(train_y-output, dw2.T).T , np.ones((1)))


  w1 = w1-a*dw1
  b1 = b1-a*db1
  w2 = w2-a*dw2
  b2 = b2-a*db2

Loss=np.array(L)

plt.plot(Loss)
plt.show()

w1 = np.random.uniform(-1, 1, ( 28*28, 128))
b1 = np.random.uniform(-1, 1, ( 128))

w2 = np.random.uniform(-1, 1, (128, 10))
b2 = np.random.uniform(-1, 1, (10))



#monte calro


L = []

a = 0.001

for i in range(5000):

  L1 = np.add(np.matmul(train_x, w1), b1)
  L2 = np.add(np.matmul(L1, w2), b2)

  output = softmax(L2)


  predict = np.max(output)
  target = np.max(train_y)


  loss = -target*np.log(predict)



  w1_ = w1-a*(2*np.random.random()-1)
  b1_ = b1-a*(2*np.random.random()-1)
  w2_ = w2-a*(2*np.random.random()-1)
  b2_ = b2-a*(2*np.random.random()-1)

  L1_ = np.add(np.matmul(train_x, w1_), b1_)
  L2_ = np.add(np.matmul(L1_, w2_), b2_)

  output_ = softmax(L2_)


  predict_ = np.max(output_)
  target_ = np.max(train_y)


  loss_ = -target*np.log(predict_)

  if loss_ < 0:
    break


  delta = loss_-loss

  if loss_<= loss:
    w1 = w1_
    b1 = b1_
    w2 = w2_
    b2 = b2_
    L.append(loss_)

  elif np.exp(-delta)>= np.random.random():
    w1 = w1_
    b1 = b1_
    w2 = w2_
    b2 = b2_
    L.append(loss_)

  else:
    L.append(loss)
    


Loss=np.array(L)

plt.plot(Loss)
plt.show()

